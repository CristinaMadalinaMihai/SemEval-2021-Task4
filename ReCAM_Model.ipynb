{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqFip-DYsFaj"
      },
      "source": [
        "# * * * ReCAM: Reading Comprehension of Abstract Meaning * * *\n",
        "\n",
        "## * * * * * * * * * * License Thesis * * * * * * * * * *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_hcWad6oH5x"
      },
      "source": [
        "### Load Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5TZLZvJoSBn"
      },
      "source": [
        "*  load the available dataset provided by the SemEval-2021 competition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L09mtyd1xJmm",
        "outputId": "ec667522-52ec-4b67-8c97-ac48e7f8b703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemEval2021-Reading-Comprehension-of-Abstract-Meaning'...\n",
            "remote: Enumerating objects: 153, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 153 (delta 9), reused 7 (delta 7), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (153/153), 13.12 MiB | 8.74 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/boyuanzheng010/SemEval2021-Reading-Comprehension-of-Abstract-Meaning.git  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWI2oKbDoqci"
      },
      "source": [
        "*  install the necessary Python APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrT0CkRmUSeG",
        "outputId": "ca1bef2a-3f45-4b71-950d-dbec853f14fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 22.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 15.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 29.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyXcsEPho26W"
      },
      "source": [
        "*  import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nIMvJ4mdjQJN"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import random\n",
        "from tqdm import tqdm, trange\n",
        "import csv\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O5CduYCo_Pp"
      },
      "source": [
        "*  prepare a logging mechanism to log the necessary results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "90KOUtTkjWwm"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(filename='/output.log', \n",
        "                    filemode='w',\n",
        "                    format = '%(asctime)s :: %(levelname)s :: %(message)s',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGpgx1H4pyKg"
      },
      "source": [
        "*  initialize the model's arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5misXCp6kV83"
      },
      "outputs": [],
      "source": [
        "# Arguments\n",
        "max_seq_length = 256 # we cannot use 512 token because => 'CUDA out of memory'\n",
        "train_batch_size = 8 #16 => the smaller, the less the probability to get a memory outrage\n",
        "eval_batch_size = 8       \n",
        "learning_rate = 1e-5      \n",
        "num_train_epochs = 2            # Epochs - less epochs to be used for BERT\n",
        "warmup_proportion = 0.1         # How to use? depends on the optimizer\n",
        "seed = 42                       # Random seed, distil bert\n",
        "optimize_on_cpu = True          # Whether to perform optimization and keep the optimizer averages on CPU\n",
        "fp16 = True                     # Whether to use 16-bit float precision instead of 32-bit\n",
        "                                # see the NVIDIA doc\n",
        "loss_scale = 128                # Loss scaling, positive power of 2 values can improve fp16 convergence\n",
        "gradient_accumulation_steps = 1 \n",
        "weight_decay_rate = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ItVix4p5_X"
      },
      "source": [
        "*  define the file paths to each set of data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6HbEl1t0kV-c"
      },
      "outputs": [],
      "source": [
        "# ~ original\n",
        "\n",
        "data_file_path = './SemEval2021-Reading-Comprehension-of-Abstract-Meaning/data/'\n",
        "test_data_relative_path = 'trail_data/'\n",
        "train_data_relative_path = 'training_data/'\n",
        "\n",
        "# Imperceptibility\n",
        "task_1_train_data_file_path = data_file_path + train_data_relative_path + 'Task_1_train.jsonl'\n",
        "task_1_dev_data_file_path = data_file_path + train_data_relative_path + 'Task_1_dev.jsonl'\n",
        "task_1_test_data_file_path = data_file_path + test_data_relative_path + 'Task_1_Imperceptibility.jsonl'\n",
        "\n",
        "# Nonspecificity\n",
        "task_2_train_data_file_path = data_file_path + train_data_relative_path + 'Task_2_train.jsonl'\n",
        "task_2_dev_data_file_path = data_file_path + train_data_relative_path + 'Task_2_dev.jsonl'\n",
        "task_2_test_data_file_path = data_file_path + test_data_relative_path + 'Task_2_Nonspecificity.jsonl'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCJ-ju5q2Cs"
      },
      "source": [
        "### Necessary functions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eD_4T0brKuY"
      },
      "source": [
        "*     read samples from jsonl file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jk9vOcizq7x0"
      },
      "outputs": [],
      "source": [
        "# ~ original\n",
        "def read_dataset_from_jsonl_file(file_name):\n",
        "  with open(file_name, 'r', encoding = 'utf-8') as json_line_file_pointer:\n",
        "      dataset_list = list(json_line_file_pointer)\n",
        "\n",
        "      dataset_elements = []\n",
        "      for element in dataset_list:\n",
        "          parsed_result = json.loads(element)\n",
        "\n",
        "          dataset_elements.append({\n",
        "              \"article\" : parsed_result['article'],\n",
        "              \"question\" : parsed_result['question'],\n",
        "              \"options\" : [parsed_result['option_0'], parsed_result['option_1'], parsed_result['option_2'], parsed_result['option_3'], parsed_result['option_4']],\n",
        "              \"label\" : int(parsed_result['label']) \n",
        "          })\n",
        "\n",
        "  return dataset_elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko8E8Q2VrY6Q"
      },
      "source": [
        "*    pre-process input features structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9lSTF7rmrZlU"
      },
      "outputs": [],
      "source": [
        "class InputFeatures(object):\n",
        "    def __init__(self, features , masked_labels, options, label):\n",
        "        \n",
        "        self.choices_features = []\n",
        "        for _, input_ids, input_mask in features: \n",
        "          self.choices_features.append({\n",
        "              'input_ids': input_ids,\n",
        "              'input_mask': input_mask\n",
        "          })\n",
        "\n",
        "        self.masked_labels = masked_labels\n",
        "        self.options = options\n",
        "        self.label = label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1AJYVa6sRyM"
      },
      "source": [
        "*     pre-process samples and convert them into features to serve as input for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z6GiCaX9sR_A"
      },
      "outputs": [],
      "source": [
        "def convert_samples_into_features(samples, tokenizer, max_seq_length):\n",
        "    \n",
        "    features = []\n",
        "    masking_token_id = tokenizer.mask_token_id\n",
        "    masking_token = tokenizer.mask_token\n",
        "    classification_token = \"[CLS]\"\n",
        "    separation_token = \"[SEP]\"\n",
        "\n",
        "    for sample_index, sample in enumerate(samples):\n",
        "        choices_features = []\n",
        "\n",
        "        article_tokens = tokenizer.tokenize(sample['article'])\n",
        "        question_tokens = tokenizer.tokenize(sample['question'].replace(\"@placeholder\", masking_token))\n",
        "\n",
        "        options = []\n",
        "        for option in sample['options']:\n",
        "            article_tokens_option = article_tokens[:]\n",
        "            question_tokens_option = question_tokens + tokenizer.tokenize(option) \n",
        "        \n",
        "            _truncate_seq_pair(article_tokens_option, question_tokens_option, max_seq_length - 3)\n",
        "\n",
        "            tokens = [classification_token] + question_tokens_option + [separation_token] + article_tokens_option + [separation_token]\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)                                   \n",
        "            input_mask = [1] * len(input_ids)\n",
        "\n",
        "            padding = [0] * (max_seq_length - len(input_ids))\n",
        "            input_ids += padding\n",
        "            input_mask += padding\n",
        "\n",
        "            # Heuristic : Loss calculated only for Masked Token!\n",
        "            masked_labels = [-100 if t_id != masking_token_id else tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sample['options'][sample['label']]))[0] for t_id in input_ids]\n",
        "\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(masked_labels) == max_seq_length\n",
        "            choices_features.append((tokens, input_ids, input_mask))\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                features = choices_features,\n",
        "                masked_labels = masked_labels,\n",
        "                options = options,\n",
        "                label = sample['label']\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU9Jq1xOuglL"
      },
      "source": [
        "*  optimize the model to work on cpu based on the optimizer parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "59RTwgpUug0b"
      },
      "outputs": [],
      "source": [
        "# ~ original\n",
        "def improve_model_from_optimizer(model_parameters, optimizer_parameters):\n",
        "    for (optimizer, optimizer_parameter), (model, model_parameters) in zip(optimizer_parameters, model_parameters):\n",
        "        if optimizer == model:\n",
        "          model_parameters.data.copy_(optimizer_parameter.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phbjRAqxx7ys"
      },
      "source": [
        "*  optimize on CPU by copying the gradient of the GPU parameters to the CPU/RAMM copy of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "icamJeCyx8Cg"
      },
      "outputs": [],
      "source": [
        "def set_optimizer_params_grad(named_params_optimizer, named_params_model, test_nan=False):\n",
        "    \"\"\" Utility function for optimize_on_cpu and 16-bits training.\n",
        "        Copy the gradient of the GPU parameters to the CPU/RAMM copy of the model\n",
        "    \"\"\"\n",
        "    is_nan = False\n",
        "    for (name_opti, param_opti), (name_model, param_model) in zip(named_params_optimizer, named_params_model):\n",
        "        if name_opti != name_model:\n",
        "            logging.error(\"name_opti != name_model: {} {}\".format(name_opti, name_model))\n",
        "            raise ValueError\n",
        "        if param_model.grad is not None:\n",
        "            if test_nan and torch.isnan(param_model.grad).sum() > 0:\n",
        "                is_nan = True\n",
        "            if param_opti.grad is None:\n",
        "                param_opti.grad = torch.nn.Parameter(param_opti.data.new().resize_(*param_opti.data.size()))\n",
        "            param_opti.grad.data.copy_(param_model.grad.data)\n",
        "        else:\n",
        "            param_opti.grad = None\n",
        "    return is_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-fTccOZyjxo"
      },
      "source": [
        "*  function to extract a specific field from a feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i1NF1taQyj8y"
      },
      "outputs": [],
      "source": [
        "# ~ original\n",
        "def get_feature_specific_field(features, field):\n",
        "  feature_fields = []\n",
        "  for feature in features:\n",
        "    feature_fields.append(feature.choices_features[0][field])\n",
        "  \n",
        "  return feature_fields   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qry8oYJzmek"
      },
      "source": [
        "*  truncate article and question tokens in order to fit into the model  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oFNwATbCzmqJ"
      },
      "outputs": [],
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "def _truncate_seq(tokens_a, max_length):\n",
        "    while True:\n",
        "        if len(tokens_a) <= max_length:\n",
        "            break\n",
        "        else:\n",
        "            tokens_a.pop()\n",
        "    \n",
        "    return tokens_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp0Y92ddcSe0"
      },
      "source": [
        "### **HYPERPARAMETER FINE-TUNING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM1fkQ5ZUqsK",
        "outputId": "eb8cf2a3-0ff7-407b-9050-fe41fa563d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device:\n",
            "cuda\n",
            "device count (number of GPUs):\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "print(\"device:\")\n",
        "print(device)\n",
        "print(\"device count (number of GPUs):\")\n",
        "print(n_gpu)\n",
        "\n",
        "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
        "#Initialise seeds\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "0fb0aa342fe3461e99f5356a2ce03749",
            "9c96e428cda1414fad7dece4da38c096",
            "00ba953dd32e498d9addef0299c33f78",
            "221f0748c05c468084dfb7a831c027b8",
            "60c11f0b3b4342d8b5d97c5341d2d5fe",
            "582183d2a3274881814f6713d5851ade",
            "34985471c9d24c69bb6a631bb5975745",
            "76fc7c68b35b4bcc9afc205a09c25e7e",
            "2ae91d8aef2143ef80b8c8d3a8215fba",
            "f117b17569404c8aab00ac99c501f119",
            "8c55e3ab88984041993743cb8ecb0660",
            "18d69bb8197540cdb017229bc8c823d1",
            "889c49c42e1c4c6caf7fecdf60658e8b",
            "23be29c468ad4c8790ec2504129fd06d",
            "4e2c5cc2fafa4663bef0c9789a7899e5",
            "71497dc5a7e7489b8180c897e7814ea1",
            "a8f0aa262fb3483eaf1460238e3e1ce0",
            "f35a07c90bef451bafba4bd32bd9a569",
            "31b3303615a44d97958ccca85c711681",
            "3eba0a51068946668c1b720a1c0fbebb",
            "47fe866e39484393ae0f035ab81b99ee",
            "74708615cdf34b0f9cacf131a41b5e24",
            "cc66532bb4cf48ca8fe47d77c1b46437",
            "fb09e85e6a4447dba50a90f29f2c9a95",
            "2b7bfc06c5b74373a72e76b386fcb6e1",
            "2623e3600b2f4ec5ad399e435c2f4f9e",
            "18d94d026d574257944a25c939354723",
            "866b4f79f0e14b23b7b67804a1c91c19",
            "5c31bba28db74aba9d3b2d1585f6ae8c",
            "b318dbfc847a4df0ba996fcc205a0e20",
            "1f2f106a7a7a4af6899bbaf7cd150a27",
            "c9fd15be063b4fb1bec0050a970388a4",
            "73de73da59e14bcabe903cb50daabe78",
            "1f4e91720b474e94a1c8059e10f53af6",
            "76f2ad8cf2804a8d8aebfb6ec549e20c",
            "11036c6b1ba840e2aef020b47ef45bcb",
            "2f96d317ba404ca1b1495e554f29a42f",
            "9c0db53f9dff4832a2e23896f0a4d7a1",
            "0101c5ec84cd4339a4b28e5b7a9a9a31",
            "ed2a88c23f06402fb23d6ffeaaf429be",
            "131a7afb016c47038ac1970ec57c4f5b",
            "648a65f1f2004618a3e764836cb1b73c",
            "2be43f644efd4a59a1639f83a97913e0",
            "2676d93c348a4aa5b9e1d4d82d311d2a"
          ]
        },
        "id": "UYKRR6GHUufo",
        "outputId": "a691c7ab-78ec-4040-f906-90898ad7e7b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fb0aa342fe3461e99f5356a2ce03749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18d69bb8197540cdb017229bc8c823d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc66532bb4cf48ca8fe47d77c1b46437"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f4e91720b474e94a1c8059e10f53af6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW, BertTokenizer, BertForMaskedLM      \n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)        # Write the tokenizer to be used\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")      # Write the tokenizer to be used\n",
        "# model = DistilBertForMaskedLM.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "#model = DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')        # Write the tokenizer to be used\n",
        "# model = BertForMaskedLM.from_pretrained('bert-large-uncased')    # Write the model to be used\n",
        "\n",
        "# tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-generator')\n",
        "# model = ElectraForMaskedLM.from_pretrained('google/electra-base-discriminator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxCx46giUvD_",
        "outputId": "f6eb1718-0327-48bf-9cf1-f40f95e346c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Optimisations\n",
        "if fp16:\n",
        "    model.half()\n",
        "if n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "\n",
        "# Load Model to device (cuda here)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VKvfmtmqUy1o"
      },
      "outputs": [],
      "source": [
        "if fp16:\n",
        "    param_optimizer = [(n, param.clone().detach().to('cpu').float().requires_grad_()) \\\n",
        "                        for n, param in model.named_parameters()]\n",
        "elif optimize_on_cpu:\n",
        "    param_optimizer = [(n, param.clone().detach().to('cpu').requires_grad_()) \\\n",
        "                        for n, param in model.named_parameters()]\n",
        "else:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': weight_decay_rate},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9v_SlYSU1qB",
        "outputId": "e2856735-d9c6-4d2d-e7cc-2c1f0a1b7176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "number_of_samples = 2000\n",
        "\n",
        "train_examples = read_dataset_from_jsonl_file(task_1_train_data_file_path) # Training Examples: task_1_train_data_file_path, task_2_train_data_file_path\n",
        "train_examples = train_examples[:number_of_samples]\n",
        "\n",
        "num_train_steps = int((len(train_examples) * gradient_accumulation_steps * num_train_epochs) / train_batch_size)\n",
        "t_total = num_train_steps\n",
        "\n",
        "# Optimiser is Adam\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                         lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMHYNrP2U3Y5",
        "outputId": "a60e7921-02e5-49d3-fb9b-34c29c409821"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "global_step = 0\n",
        "train_features = convert_samples_into_features(train_examples, tokenizer, max_seq_length)\n",
        "\n",
        "logging.info(\"***** Running training *****\")\n",
        "logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "logging.info(\"  Batch size = %d\", train_batch_size)\n",
        "logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "\n",
        "# all_options = torch.tensor([f.options for f in train_features], dtype=torch.long)\n",
        "all_labels = torch.tensor([f.label for f in train_features], dtype=torch.long)\n",
        "all_masked_labels = torch.tensor([f.masked_labels for f in train_features], dtype=torch.long)\n",
        "\n",
        "all_input_ids_1 = torch.tensor(get_feature_specific_field(train_features, 'input_ids'), dtype=torch.long)\n",
        "all_input_mask_1 = torch.tensor(get_feature_specific_field(train_features, 'input_mask'), dtype=torch.long)\n",
        "#all_segment_ids_1 = torch.tensor(get_feature_specific_field(train_features, 'segment_ids'), dtype=torch.long)\n",
        "\n",
        "train_data = TensorDataset(all_input_ids_1, all_input_mask_1, all_labels, all_masked_labels) # 3rd param: all_segment_ids_1\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyxrNVaQU85k",
        "outputId": "ddaf1d6f-4f9f-46eb-954c-e3a8910c5e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/250 [00:01<06:44,  1.63s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  452.0\n",
            "\tTraining steps :  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   1%|          | 2/250 [00:02<05:02,  1.22s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  616.25\n",
            "\tTraining steps :  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   1%|          | 3/250 [00:03<04:23,  1.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  683.0\n",
            "\tTraining steps :  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   2%|▏         | 4/250 [00:04<04:05,  1.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  637.8125\n",
            "\tTraining steps :  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   2%|▏         | 5/250 [00:05<03:55,  1.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  661.45\n",
            "\tTraining steps :  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   2%|▏         | 6/250 [00:06<03:48,  1.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  678.7916666666666\n",
            "\tTraining steps :  6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   3%|▎         | 7/250 [00:07<03:44,  1.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  658.0357142857143\n",
            "\tTraining steps :  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   3%|▎         | 8/250 [00:07<03:41,  1.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  661.96875\n",
            "\tTraining steps :  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   4%|▎         | 9/250 [00:08<03:38,  1.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  660.8055555555555\n",
            "\tTraining steps :  9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   4%|▍         | 10/250 [00:09<03:35,  1.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  663.225\n",
            "\tTraining steps :  10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   4%|▍         | 11/250 [00:10<03:33,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  645.7272727272727\n",
            "\tTraining steps :  11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   5%|▍         | 12/250 [00:11<03:32,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  652.2916666666666\n",
            "\tTraining steps :  12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   5%|▌         | 13/250 [00:12<03:31,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  655.2692307692307\n",
            "\tTraining steps :  13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   6%|▌         | 14/250 [00:13<03:30,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  670.8571428571429\n",
            "\tTraining steps :  14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   6%|▌         | 15/250 [00:14<03:29,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  672.8\n",
            "\tTraining steps :  15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   6%|▋         | 16/250 [00:15<03:27,  1.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  663.40625\n",
            "\tTraining steps :  16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   7%|▋         | 17/250 [00:15<03:27,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  660.3823529411765\n",
            "\tTraining steps :  17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   7%|▋         | 18/250 [00:16<03:26,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  655.5\n",
            "\tTraining steps :  18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   8%|▊         | 19/250 [00:17<03:30,  1.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  665.2631578947369\n",
            "\tTraining steps :  19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   8%|▊         | 20/250 [00:18<03:37,  1.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  660.025\n",
            "\tTraining steps :  20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   8%|▊         | 21/250 [00:19<03:36,  1.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  672.4761904761905\n",
            "\tTraining steps :  21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   9%|▉         | 22/250 [00:20<03:31,  1.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  675.3181818181819\n",
            "\tTraining steps :  22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   9%|▉         | 23/250 [00:21<03:47,  1.00s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  676.6521739130435\n",
            "\tTraining steps :  23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  10%|▉         | 24/250 [00:23<04:02,  1.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  671.7708333333334\n",
            "\tTraining steps :  24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  10%|█         | 25/250 [00:24<04:00,  1.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  681.92\n",
            "\tTraining steps :  25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  10%|█         | 26/250 [00:24<03:47,  1.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  673.4326923076923\n",
            "\tTraining steps :  26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  11%|█         | 27/250 [00:25<03:38,  1.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  674.9166666666666\n",
            "\tTraining steps :  27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  11%|█         | 28/250 [00:26<03:31,  1.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  676.3482142857143\n",
            "\tTraining steps :  28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  12%|█▏        | 29/250 [00:27<03:25,  1.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  675.3706896551724\n",
            "\tTraining steps :  29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  12%|█▏        | 30/250 [00:28<03:22,  1.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  679.8083333333333\n",
            "\tTraining steps :  30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  12%|█▏        | 31/250 [00:29<03:19,  1.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  682.6209677419355\n",
            "\tTraining steps :  31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  13%|█▎        | 32/250 [00:30<03:16,  1.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  675.1484375\n",
            "\tTraining steps :  32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  13%|█▎        | 33/250 [00:31<03:14,  1.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  672.4924242424242\n",
            "\tTraining steps :  33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  14%|█▎        | 34/250 [00:32<03:13,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  676.3897058823529\n",
            "\tTraining steps :  34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  14%|█▍        | 35/250 [00:32<03:12,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  674.4071428571428\n",
            "\tTraining steps :  35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  14%|█▍        | 36/250 [00:33<03:10,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  675.2708333333334\n",
            "\tTraining steps :  36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  15%|█▍        | 37/250 [00:34<03:09,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  670.9121621621622\n",
            "\tTraining steps :  37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  15%|█▌        | 38/250 [00:35<03:08,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  669.046052631579\n",
            "\tTraining steps :  38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  16%|█▌        | 39/250 [00:36<03:08,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  669.3525641025641\n",
            "\tTraining steps :  39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  16%|█▌        | 40/250 [00:37<03:07,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  671.78125\n",
            "\tTraining steps :  40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  16%|█▋        | 41/250 [00:38<03:07,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  670.5914634146342\n",
            "\tTraining steps :  41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  17%|█▋        | 42/250 [00:39<03:05,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  671.7916666666666\n",
            "\tTraining steps :  42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  17%|█▋        | 43/250 [00:40<03:04,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  673.3779069767442\n",
            "\tTraining steps :  43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  18%|█▊        | 44/250 [00:40<03:03,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  671.4488636363636\n",
            "\tTraining steps :  44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  18%|█▊        | 45/250 [00:41<03:02,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  669.9944444444444\n",
            "\tTraining steps :  45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  18%|█▊        | 46/250 [00:42<03:01,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  668.125\n",
            "\tTraining steps :  46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:  19%|█▉        | 47/250 [00:43<03:00,  1.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTraining loss :  664.281914893617\n",
            "\tTraining steps :  47\n"
          ]
        }
      ],
      "source": [
        "correct_ans = 0\n",
        "wrong_list = []\n",
        "total_ans = 0\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=2000)\n",
        "\n",
        "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
        "    #model.train() #new\n",
        "\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    \n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, label, lm_label_ids = batch # 3rd arg: , segment_ids\n",
        "        \n",
        "        #optimizer.zero_grad() #new\n",
        "        \n",
        "        outputs = model(input_ids, attention_mask=input_mask, labels=lm_label_ids) #last arg: , token_type_ids = segment_ids  #TOkens with labels set to -100 are ignored             \n",
        "        loss = outputs.loss\n",
        "        # print()\n",
        "        # print(\"HELLLLOOO\")\n",
        "        # print(outputs.last_hidden_state.numpy().shape)\n",
        "\n",
        "        if n_gpu > 1:\n",
        "            loss = loss.mean() # mean() to average on multi-gpu.\n",
        "        if fp16 and loss_scale != 1.0:\n",
        "            # rescale loss for fp16 training\n",
        "            # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
        "            loss = loss * loss_scale\n",
        "        if gradient_accumulation_steps > 1:\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        #optimizer.step() #new\n",
        "        #scheduler.step() #new\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_steps += 1\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            if fp16 or optimize_on_cpu:\n",
        "                if fp16 and loss_scale != 1.0:\n",
        "                    # scale down gradients for fp16 training\n",
        "                    for param in model.parameters():\n",
        "                        if param.grad is not None:\n",
        "                            param.grad.data = param.grad.data / loss_scale\n",
        "                is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
        "                if is_nan:\n",
        "                    logging.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
        "                    loss_scale = loss_scale / 2\n",
        "                    model.zero_grad()\n",
        "                    continue\n",
        "                optimizer.step()\n",
        "                improve_model_from_optimizer(model.named_parameters(), param_optimizer)\n",
        "            else:\n",
        "                optimizer.step()\n",
        "\n",
        "            train_loss = tr_loss / nb_tr_steps\n",
        "            print(\"\\tTraining loss : \", train_loss)\n",
        "            print(\"\\tTraining steps : \", nb_tr_steps)\n",
        "\n",
        "            model.zero_grad()\n",
        "            global_step += 1\n",
        "            \n",
        "          \n",
        "# torch.save({\n",
        "#     'model': model.state_dict()\n",
        "# }, 'saved_file_3.txt')\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7S3D1MWVbU_"
      },
      "outputs": [],
      "source": [
        "# torch.save({\n",
        "#     'model': model.state_dict()\n",
        "# }, 'saved_file_epoch1.txt')\n",
        "\n",
        "# number_of_test_samples = 1000\n",
        "dev_examples_task_1 = read_dataset_from_jsonl_file(task_1_dev_data_file_path)\n",
        "# dev_examples_task_1 = dev_examples_task_1[:number_of_test_samples] \n",
        "\n",
        "test_examples_task_1 = read_dataset_from_jsonl_file(task_1_test_data_file_path)\n",
        "# test_examples_task_1 = test_examples_task_1[:number_of_test_samples]\n",
        "\n",
        "\n",
        "\n",
        "dev_examples_task_2 = read_dataset_from_jsonl_file(task_2_dev_data_file_path)\n",
        "# dev_examples_task_2 = dev_examples_task_2[:number_of_test_samples] \n",
        "\n",
        "test_examples_task_2 = read_dataset_from_jsonl_file(task_2_test_data_file_path)\n",
        "# test_examples_task_2 = test_examples_task_2[:number_of_test_samples]\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa-GJOKaLTO9"
      },
      "outputs": [],
      "source": [
        "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qq-cPVuVdik"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(examples):\n",
        "  correct_score = 0\n",
        "  wrong_list = []\n",
        "  \n",
        "  for idx, example in enumerate(examples) :\n",
        "\n",
        "      article = example['article']\n",
        "      ques_tokens = tokenizer.tokenize(example['question'].replace(\"@placeholder\", tokenizer.mask_token))        \n",
        "      tokenized_article = tokenizer.tokenize(article)\n",
        "\n",
        "      _truncate_seq_pair(tokenized_article, ques_tokens, max_seq_length - 1)\n",
        "\n",
        "      tokens =  [tokenizer.cls_token] + ques_tokens + [tokenizer.sep_token] + tokenized_article + [tokenizer.sep_token]\n",
        "\n",
        "      # tokens =  ques_tokens + [tokenizer.sep_token]\n",
        "\n",
        "      masked_index = tokens.index(tokenizer.mask_token)\n",
        "\n",
        "\n",
        "      candidates = example['options']\n",
        "      candidates_ids = []\n",
        "      for c in candidates:\n",
        "          candidates_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(c))[0])\n",
        "\n",
        "\n",
        "      indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)        \n",
        "      segments_ids = [0] * (len(ques_tokens) + 2) + [1] * (len(tokenized_article) + 1)\n",
        "      input_mask = [1] * len(indexed_tokens)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      padding = [0] * (max_seq_length - len(indexed_tokens))\n",
        "      indexed_tokens += padding#[tokenizer.pad_token_id] * len(padding)\n",
        "      input_mask += padding\n",
        "      segments_ids += padding\n",
        "      \n",
        "\n",
        "      tokens_tensor = torch.tensor([indexed_tokens])\n",
        "      #segments_tensors = torch.tensor([segments_ids])\n",
        "      mask_tensors = torch.tensor([input_mask])\n",
        "      \n",
        "      mask_tensors = mask_tensors.to(device)\n",
        "      tokens_tensor = tokens_tensor.to(device)\n",
        "      #segments_tensors = segments_tensors.to(device)\n",
        "\n",
        "\n",
        "      predictions = model(input_ids = tokens_tensor, attention_mask=mask_tensors) # last arg: , token_type_ids = segments_tensors\n",
        "      predictions_candidates = predictions.logits[0, masked_index, candidates_ids]\n",
        "      answer_idx = torch.argmax(predictions_candidates).item()\n",
        "      #print(answer_idx)\n",
        "      \n",
        "      \n",
        "      #print(\"Correct answer : \", answer_idx, \"\\tLabel :\", example['label'], '\\n') \n",
        "      if(answer_idx == example['label']):\n",
        "          correct_score += 1\n",
        "      else :\n",
        "          wrong_list.append(idx)\n",
        "\n",
        "  return correct_score / len(examples)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqq7IspTyo-C"
      },
      "outputs": [],
      "source": [
        "accurary_task_1_dev = compute_accuracy(dev_examples_task_1)\n",
        "accurary_task_1_test = compute_accuracy(test_examples_task_1)\n",
        "\n",
        "accurary_task_3_dev = compute_accuracy(dev_examples_task_2)\n",
        "accurary_task_3_test = compute_accuracy(test_examples_task_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzAuswSWwr6q"
      },
      "outputs": [],
      "source": [
        "with open('outfile.csv', 'w') as f :\n",
        "      writer = csv.writer(f, delimiter = ',')\n",
        "      writer.writerow(['Train task', 'Evaluation task', 'Epochs', 'Learning rate', 'Weight decay rate', 'Accurary','Model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I68P2FrmgMs9"
      },
      "outputs": [],
      "source": [
        "with open('outfile.csv', 'a') as f :\n",
        "      writer = csv.writer(f, delimiter = ',')\n",
        "\n",
        "      writer.writerow(['task 1', 'task 1 dev', num_train_epochs, learning_rate, weight_decay_rate, accurary_task_1_dev, 'bert-base-uncased'])\n",
        "      writer.writerow(['task 1', 'task 1 test', num_train_epochs, learning_rate, weight_decay_rate, accurary_task_1_test, 'bert-base-uncased'])\n",
        "\n",
        "      writer.writerow(['task 1', 'task 2 dev', num_train_epochs, learning_rate, weight_decay_rate, accurary_task_3_dev, 'bert-base-uncased'])\n",
        "      writer.writerow(['task 1', 'task 2 test', num_train_epochs, learning_rate, weight_decay_rate, accurary_task_3_test, 'bert-base-uncased'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "55BpdmDPVk6R"
      },
      "outputs": [],
      "source": [
        "# accuracy = correct_score / len(examples)  \n",
        "# print(\"Accuracy :\", accuracy)\n",
        "# print(\"Correct answers :\", correct_score) \n",
        "\n",
        "# print(\"total input items: 1000\")\n",
        "# print(\"wrong list items length :\\n\", len(wrong_list)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJIiofgscbXp"
      },
      "source": [
        "### **LOGISTIC REGRESSION **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiRNdtMgd8Jx"
      },
      "source": [
        "*  function for pre-processing the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5LBNGiQd79x"
      },
      "outputs": [],
      "source": [
        "log_regr_max_samples = 500\n",
        "\n",
        "def prepare_first_data_grouping(dataset_list):\n",
        "  \n",
        "  input_data = []\n",
        "  labels = []\n",
        "  for element in dataset_list[:log_regr_max_samples]:\n",
        "\n",
        "    first = element['question'].replace(\"@placeholder\", element['options'][0])\n",
        "    second = element['question'].replace(\"@placeholder\", element['options'][1])\n",
        "    third = element['question'].replace(\"@placeholder\", element['options'][2])\n",
        "    forth = element['question'].replace(\"@placeholder\", element['options'][3])\n",
        "    fifth = element['question'].replace(\"@placeholder\", element['options'][4])\n",
        "\n",
        "    input_data.append(\n",
        "        first + ' '+ element['article']\n",
        "    )\n",
        "    input_data.append(\n",
        "        second + ' '+ element['article']\n",
        "    )\n",
        "    input_data.append(\n",
        "        third + ' '+ element['article']\n",
        "    )\n",
        "    input_data.append(\n",
        "        forth + ' '+ element['article']\n",
        "    )\n",
        "    input_data.append(\n",
        "        fifth + ' '+ element['article']\n",
        "    )\n",
        "\n",
        "    label = int(element['label'])\n",
        "    if (label == 0):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "\n",
        "    if (label == 1):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "    \n",
        "    if (label == 2):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "\n",
        "    if (label == 3):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "\n",
        "    if (label == 4):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "  \n",
        "  return input_data, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nYr3eJhhiBa"
      },
      "source": [
        "*  read and pre-process test, dev and test samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "IX_y-nbbiIms",
        "outputId": "09de0b72-3cb3-4bcd-f410-11706e7383e0"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d8885045a039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_task_1_dataset_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset_from_jsonl_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_1_train_data_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_task_1_dataset_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset_from_jsonl_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_1_dev_data_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_task_1_dataset_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset_from_jsonl_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_1_test_data_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprocessed_train_data_task_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_task_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_first_data_grouping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_task_1_dataset_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-bc4543f4f169>\u001b[0m in \u001b[0;36mread_dataset_from_jsonl_file\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0;34m\"question\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0;34m\"options\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'option_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'option_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'option_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'option_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'option_4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m               \u001b[0;34m\"label\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m           })\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ],
      "source": [
        "# task 1\n",
        "train_task_1_dataset_list = read_dataset_from_jsonl_file(task_1_train_data_file_path) \n",
        "dev_task_1_dataset_list = read_dataset_from_jsonl_file(task_1_dev_data_file_path) \n",
        "test_task_1_dataset_list = read_dataset_from_jsonl_file(task_1_test_data_file_path) \n",
        "\n",
        "processed_train_data_task_1, train_labels_task_1 = prepare_first_data_grouping(train_task_1_dataset_list)\n",
        "processed_dev_data_task_1, dev_labels_task_1 = prepare_first_data_grouping(dev_task_1_dataset_list)\n",
        "processed_test_data_task_1, test_labels_task_1 = prepare_first_data_grouping(test_task_1_dataset_list)\n",
        "\n",
        "#task 2\n",
        "train_task_2_dataset_list = read_dataset_from_jsonl_file(task_2_train_data_file_path) \n",
        "dev_task_2_dataset_list = read_dataset_from_jsonl_file(task_2_dev_data_file_path) \n",
        "test_task_2_dataset_list = read_dataset_from_jsonl_file(task_2_test_data_file_path) \n",
        "\n",
        "processed_train_data_task_2, train_labels_task_2 = prepare_first_data_grouping(train_task_2_dataset_list)\n",
        "processed_dev_data_task_2, dev_labels_task_2 = prepare_first_data_grouping(dev_task_2_dataset_list)\n",
        "processed_test_data_task_2, test_labels_task_2 = prepare_first_data_grouping(test_task_2_dataset_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Us89iIDhn4y"
      },
      "source": [
        "*  load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Q1rSJRH7rXP9",
        "outputId": "660bdcbf-7e1b-4e7c-cd4a-cadfb7873f37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "645629bdd6eb49e08d3741f407c4d74f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68a7b9be6a44476eaee238e325116d4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540a4cb742c2408ca3ae9c1ef128e6df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n",
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1487e52e0b914a7ea1a0124913ffd973",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertModel: ['distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.embeddings.LayerNorm.weight', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel, AdamW       \n",
        "\n",
        "pretrained_weights = 'distilbert-base-uncased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights, do_lower_case=True) \n",
        "model = BertModel.from_pretrained(pretrained_weights) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mJLI_azhr0b"
      },
      "source": [
        "*  tokenize the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HB279FIrqT0",
        "outputId": "1841f6a5-841c-46ce-822e-9c8c6a084d5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize_samples(samples):\n",
        "  tokenized = []\n",
        "  for sample in samples:\n",
        "    original_tokenized = tokenizer.encode(sample, add_special_tokens=True)\n",
        "    truncated_tokenized = _truncate_seq_pair(original_tokenized, 512)\n",
        "    tokenized.append(truncated_tokenized) \n",
        "\n",
        "  return tokenized\n",
        "\n",
        "tokenized_train_data_task_1 = tokenize_samples(processed_train_data_task_1)\n",
        "tokenized_dev_data_task_1 = tokenize_samples(processed_dev_data_task_1)\n",
        "tokenized_test_data_task_1 = tokenize_samples(processed_test_data_task_1)\n",
        "\n",
        "tokenized_train_data_task_2 = tokenize_samples(processed_train_data_task_2)\n",
        "tokenized_dev_data_task_2 = tokenize_samples(processed_dev_data_task_2)\n",
        "tokenized_test_data_task_2 = tokenize_samples(processed_test_data_task_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRRuK_vKk9dq"
      },
      "source": [
        "*  add padding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5zc9dVutT7F"
      },
      "outputs": [],
      "source": [
        "def add_padding(tokenized):\n",
        "  max_len = 0\n",
        "  for t in tokenized:\n",
        "      if len(t) > max_len:\n",
        "          max_len = len(t)\n",
        "\n",
        "  padded = np.array([t + [0]*(max_len-len(t)) for t in tokenized])\n",
        "  \n",
        "  return padded\n",
        "\n",
        "padded_train_data_task_1  = add_padding(tokenized_train_data_task_1)\n",
        "padded_dev_data_task_1  = add_padding(tokenized_dev_data_task_1)\n",
        "padded_test_data_task_1  = add_padding(tokenized_test_data_task_1)\n",
        "\n",
        "padded_train_data_task_2  = add_padding(tokenized_train_data_task_2)\n",
        "padded_dev_data_task_2  = add_padding(tokenized_dev_data_task_2)\n",
        "padded_test_data_task_2  = add_padding(tokenized_test_data_task_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WDr0c-iD3bN"
      },
      "source": [
        "*  test token sequence size after padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq-M7PQ0rXqL",
        "outputId": "56d3c76f-5957-482a-833b-6d751ae854ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2500, 512)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(padded_train_data_task_1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sYhaZmSD-tJ"
      },
      "source": [
        "*  build the attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga79x6NutTCV",
        "outputId": "97d79ea9-f07c-4b9f-bd44-1c969c243c9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2500, 512)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_mask_train_data_task_1 = np.where(padded_train_data_task_1 != 0, 1, 0)\n",
        "attention_mask_dev_data_task_1 = np.where(padded_dev_data_task_1 != 0, 1, 0)\n",
        "attention_mask_test_data_task_1 = np.where(padded_test_data_task_1 != 0, 1, 0)\n",
        "\n",
        "attention_mask_train_data_task_2 = np.where(padded_train_data_task_2 != 0, 1, 0)\n",
        "attention_mask_dev_data_task_2 = np.where(padded_dev_data_task_2 != 0, 1, 0)\n",
        "attention_mask_test_data_task_2 = np.where(padded_test_data_task_2 != 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "926pyt3PEK8X"
      },
      "source": [
        "*  test attention mask shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FiOjARBEOFY"
      },
      "outputs": [],
      "source": [
        "attention_mask_train_data_task_1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMUq7Fx9EcOM"
      },
      "source": [
        "*  convert input ids and attention mask into tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib3LMccZCX9O"
      },
      "outputs": [],
      "source": [
        "input_ids_train_data_task_1 = torch.tensor(padded_train_data_task_1) \n",
        "input_ids_dev_data_task_1 = torch.tensor(padded_dev_data_task_1) \n",
        "input_ids_test_data_task_1 = torch.tensor(padded_test_data_task_1) \n",
        "\n",
        "input_ids_train_data_task_2 = torch.tensor(padded_train_data_task_2) \n",
        "input_ids_dev_data_task_2 = torch.tensor(padded_dev_data_task_2) \n",
        "input_ids_test_data_task_2 = torch.tensor(padded_test_data_task_2) \n",
        "\n",
        "attention_mask_train_data_task_1 = torch.tensor(attention_mask_train_data_task_1)\n",
        "attention_mask_dev_data_task_1 = torch.tensor(attention_mask_dev_data_task_1)\n",
        "attention_mask_test_data_task_1 = torch.tensor(attention_mask_test_data_task_1)\n",
        "\n",
        "attention_mask_train_data_task_2 = torch.tensor(attention_mask_train_data_task_2)\n",
        "attention_mask_dev_data_task_2 = torch.tensor(attention_mask_dev_data_task_2)\n",
        "attention_mask_test_data_task_2 = torch.tensor(attention_mask_test_data_task_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dP4oyChh_xq"
      },
      "source": [
        "*  prepare train, dev and test data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGmiC7iICXMF"
      },
      "outputs": [],
      "source": [
        "train_data_task_1 = TensorDataset(input_ids_train_data_task_1, attention_mask_train_data_task_1)\n",
        "train_sampler_task_1 = RandomSampler(train_data_task_1)\n",
        "train_dataloader_task_1 = DataLoader(train_data_task_1, sampler=train_sampler_task_1, batch_size=train_batch_size)\n",
        "\n",
        "dev_data_task_1 = TensorDataset(input_ids_dev_data_task_1, attention_mask_dev_data_task_1)\n",
        "dev_sampler_task_1 = RandomSampler(dev_data_task_1)\n",
        "dev_dataloader_task_1 = DataLoader(dev_data_task_1, sampler=dev_sampler_task_1, batch_size=train_batch_size)\n",
        "\n",
        "test_data_task_1 = TensorDataset(input_ids_test_data_task_1, attention_mask_test_data_task_1)\n",
        "test_sampler_task_1 = RandomSampler(test_data_task_1)\n",
        "test_dataloader_task_1 = DataLoader(test_data_task_1, sampler=test_sampler_task_1, batch_size=train_batch_size)\n",
        "\n",
        "\n",
        "train_data_task_2 = TensorDataset(input_ids_train_data_task_2, attention_mask_train_data_task_2)\n",
        "train_sampler_task_2 = RandomSampler(train_data_task_2)\n",
        "train_dataloader_task_2 = DataLoader(train_data_task_2, sampler=train_sampler_task_2, batch_size=train_batch_size)\n",
        "\n",
        "dev_data_task_2 = TensorDataset(input_ids_dev_data_task_2, attention_mask_dev_data_task_2)\n",
        "dev_sampler_task_2 = RandomSampler(dev_data_task_2)\n",
        "dev_dataloader_task_2 = DataLoader(dev_data_task_2, sampler=dev_sampler_task_2, batch_size=train_batch_size)\n",
        "\n",
        "test_data_task_2 = TensorDataset(input_ids_test_data_task_2, attention_mask_test_data_task_2)\n",
        "test_sampler_task_2 = RandomSampler(test_data_task_2)\n",
        "test_dataloader_task_2 = DataLoader(test_data_task_2, sampler=test_sampler_task_2, batch_size=train_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOmwkUbhjO-L"
      },
      "source": [
        "*  get vector representation of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zvz7WS3t5YE",
        "outputId": "2bba5f83-dccb-431c-9fa1-c8d4f710f92d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 625/625 [33:15<00:00,  3.19s/it]\n"
          ]
        }
      ],
      "source": [
        "def getModelFeatures(train_dataloader):\n",
        "  features = []\n",
        "  for i in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
        "    print(i)\n",
        "    with torch.no_grad():\n",
        "      for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "              input_ids, input_mask = batch\n",
        "\n",
        "              outputs = model(input_ids, attention_mask=input_mask)\n",
        "              outputs.last_hidden_state.numpy().shape\n",
        "\n",
        "              if (i == num_train_epochs):\n",
        "                features.append(outputs.last_hidden_state[:,0,:].numpy())\n",
        "    \n",
        "  return features\n",
        "\n",
        "features_train_task_1 = getModelFeatures(train_dataloader_task_1)\n",
        "features_dev_task_1 = getModelFeatures(dev_dataloader_task_1)\n",
        "features_test_task_1 = getModelFeatures(test_dataloader_task_1)\n",
        "\n",
        "features_train_task_2 = getModelFeatures(train_dataloader_task_2)\n",
        "features_dev_task_2 = getModelFeatures(dev_dataloader_task_2)\n",
        "features_test_task_2 = getModelFeatures(test_dataloader_task_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRbm2hFRmM4U"
      },
      "source": [
        "*  append feature batches "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryVOsuTTRvFh",
        "outputId": "7cf60295-df92-44ff-e4f1-5a8579b3a2a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2500\n"
          ]
        }
      ],
      "source": [
        "def append_feature_batches(features):\n",
        "  all_features = np.append(features[0], features[1], axis=0)\n",
        "  for index, feature in enumerate(features):\n",
        "    if (index != 0 and index != 1):\n",
        "      all_features = np.append(all_features, features[index], axis=0)\n",
        "  \n",
        "  return all_features\n",
        "\n",
        "all_features_train_task_1 = append_feature_batches(features_train_task_1)\n",
        "all_features_dev_task_1 = append_feature_batches(features_dev_task_1)\n",
        "all_features_test_task_1 = append_feature_batches(features_test_task_1)\n",
        "\n",
        "all_features_train_task_2 = append_feature_batches(features_train_task_2)\n",
        "all_features_dev_task_2 = append_feature_batches(features_dev_task_2)\n",
        "all_features_test_task_2 = append_feature_batches(features_test_task_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFPIUPs2mmVn"
      },
      "source": [
        "*  import LogRegr libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwSPiXJ-ku1_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF5d7mbIz070",
        "outputId": "e83aef9e-3656-4915-9477-c4d9e196f255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 0.0001}\n",
            "best scrores:  0.7978666666666667\n"
          ]
        }
      ],
      "source": [
        "def get_grid_search_best_parameter(features, labels):\n",
        "  grid_search = GridSearchCV(LogisticRegression(max_iter = 10000), {'C': np.linspace(0.000001, 1000, 20)})\n",
        "  grid_search.fit(features, labels)\n",
        "\n",
        "  return grid_search.best_params_\n",
        "\n",
        "C_train_task_1 = get_grid_search_best_parameter(all_features_train_task_1, train_labels_task_1)\n",
        "# C_dev_task_1 = get_grid_search_best_parameter(all_features_dev_task_1, dev_labels_task_1)\n",
        "# C_test_task_1 = get_grid_search_best_parameter(all_features_test_task_1, test_labels_task_1)\n",
        "\n",
        "C_train_task_2 = get_grid_search_best_parameter(all_features_train_task_2, train_labels_task_2)\n",
        "# C_dev_task_2 = get_grid_search_best_parameter(all_features_dev_task_2, dev_labels_task_2)\n",
        "# C_test_task_2 = get_grid_search_best_parameter(all_features_test_task_2, test_labels_task_2)\n",
        "#  print('best parameters: ', grid_search.best_params_)\n",
        "#  print('best scrores: ', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxDrYxlZz1Ii",
        "outputId": "0d59302e-6f18-47d6-d001-28288142927a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.0001, max_iter=3000)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_clf = LogisticRegression(max_iter = 3000, C = C_train_task_1)\n",
        "lr_clf.fit(all_features_train_task_1, train_labels_task_1)\n",
        "dev_task_1_accuracy = lr_clf.score(all_features_dev_task_1, dev_labels_task_1)\n",
        "test_task_1_accuracy = lr_clf.score(all_features_test_task_1, test_labels_task_1)\n",
        "\n",
        "print(\"task 1:\")\n",
        "print(\"dev:\")\n",
        "print(dev_task_1_accuracy)\n",
        "print(\"test:\")\n",
        "print(test_task_1_accuracy)\n",
        "\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter = 3000, C = C_train_task_2)\n",
        "lr_clf.fit(all_features_train_task_2, train_labels_task_2)\n",
        "dev_task_2_accuracy = lr_clf.score(all_features_dev_task_2, dev_labels_task_2)\n",
        "test_task_2_accuracy = lr_clf.score(all_features_test_task_2, test_labels_task_2)\n",
        "\n",
        "print(\"task 2:\")\n",
        "print(\"dev:\")\n",
        "print(dev_task_2_accuracy)\n",
        "print(\"test:\")\n",
        "print(test_task_2_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JJIiofgscbXp"
      ],
      "name": "BERT_MLM_Model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fb0aa342fe3461e99f5356a2ce03749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c96e428cda1414fad7dece4da38c096",
              "IPY_MODEL_00ba953dd32e498d9addef0299c33f78",
              "IPY_MODEL_221f0748c05c468084dfb7a831c027b8"
            ],
            "layout": "IPY_MODEL_60c11f0b3b4342d8b5d97c5341d2d5fe"
          }
        },
        "9c96e428cda1414fad7dece4da38c096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_582183d2a3274881814f6713d5851ade",
            "placeholder": "​",
            "style": "IPY_MODEL_34985471c9d24c69bb6a631bb5975745",
            "value": "Downloading: 100%"
          }
        },
        "00ba953dd32e498d9addef0299c33f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fc7c68b35b4bcc9afc205a09c25e7e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ae91d8aef2143ef80b8c8d3a8215fba",
            "value": 231508
          }
        },
        "221f0748c05c468084dfb7a831c027b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f117b17569404c8aab00ac99c501f119",
            "placeholder": "​",
            "style": "IPY_MODEL_8c55e3ab88984041993743cb8ecb0660",
            "value": " 226k/226k [00:00&lt;00:00, 308kB/s]"
          }
        },
        "60c11f0b3b4342d8b5d97c5341d2d5fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582183d2a3274881814f6713d5851ade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34985471c9d24c69bb6a631bb5975745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76fc7c68b35b4bcc9afc205a09c25e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae91d8aef2143ef80b8c8d3a8215fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f117b17569404c8aab00ac99c501f119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c55e3ab88984041993743cb8ecb0660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18d69bb8197540cdb017229bc8c823d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_889c49c42e1c4c6caf7fecdf60658e8b",
              "IPY_MODEL_23be29c468ad4c8790ec2504129fd06d",
              "IPY_MODEL_4e2c5cc2fafa4663bef0c9789a7899e5"
            ],
            "layout": "IPY_MODEL_71497dc5a7e7489b8180c897e7814ea1"
          }
        },
        "889c49c42e1c4c6caf7fecdf60658e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8f0aa262fb3483eaf1460238e3e1ce0",
            "placeholder": "​",
            "style": "IPY_MODEL_f35a07c90bef451bafba4bd32bd9a569",
            "value": "Downloading: 100%"
          }
        },
        "23be29c468ad4c8790ec2504129fd06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b3303615a44d97958ccca85c711681",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3eba0a51068946668c1b720a1c0fbebb",
            "value": 28
          }
        },
        "4e2c5cc2fafa4663bef0c9789a7899e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47fe866e39484393ae0f035ab81b99ee",
            "placeholder": "​",
            "style": "IPY_MODEL_74708615cdf34b0f9cacf131a41b5e24",
            "value": " 28.0/28.0 [00:00&lt;00:00, 214B/s]"
          }
        },
        "71497dc5a7e7489b8180c897e7814ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f0aa262fb3483eaf1460238e3e1ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35a07c90bef451bafba4bd32bd9a569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31b3303615a44d97958ccca85c711681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eba0a51068946668c1b720a1c0fbebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47fe866e39484393ae0f035ab81b99ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74708615cdf34b0f9cacf131a41b5e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc66532bb4cf48ca8fe47d77c1b46437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb09e85e6a4447dba50a90f29f2c9a95",
              "IPY_MODEL_2b7bfc06c5b74373a72e76b386fcb6e1",
              "IPY_MODEL_2623e3600b2f4ec5ad399e435c2f4f9e"
            ],
            "layout": "IPY_MODEL_18d94d026d574257944a25c939354723"
          }
        },
        "fb09e85e6a4447dba50a90f29f2c9a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866b4f79f0e14b23b7b67804a1c91c19",
            "placeholder": "​",
            "style": "IPY_MODEL_5c31bba28db74aba9d3b2d1585f6ae8c",
            "value": "Downloading: 100%"
          }
        },
        "2b7bfc06c5b74373a72e76b386fcb6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b318dbfc847a4df0ba996fcc205a0e20",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f2f106a7a7a4af6899bbaf7cd150a27",
            "value": 570
          }
        },
        "2623e3600b2f4ec5ad399e435c2f4f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9fd15be063b4fb1bec0050a970388a4",
            "placeholder": "​",
            "style": "IPY_MODEL_73de73da59e14bcabe903cb50daabe78",
            "value": " 570/570 [00:00&lt;00:00, 4.80kB/s]"
          }
        },
        "18d94d026d574257944a25c939354723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866b4f79f0e14b23b7b67804a1c91c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c31bba28db74aba9d3b2d1585f6ae8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b318dbfc847a4df0ba996fcc205a0e20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f2f106a7a7a4af6899bbaf7cd150a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9fd15be063b4fb1bec0050a970388a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73de73da59e14bcabe903cb50daabe78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4e91720b474e94a1c8059e10f53af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76f2ad8cf2804a8d8aebfb6ec549e20c",
              "IPY_MODEL_11036c6b1ba840e2aef020b47ef45bcb",
              "IPY_MODEL_2f96d317ba404ca1b1495e554f29a42f"
            ],
            "layout": "IPY_MODEL_9c0db53f9dff4832a2e23896f0a4d7a1"
          }
        },
        "76f2ad8cf2804a8d8aebfb6ec549e20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0101c5ec84cd4339a4b28e5b7a9a9a31",
            "placeholder": "​",
            "style": "IPY_MODEL_ed2a88c23f06402fb23d6ffeaaf429be",
            "value": "Downloading: 100%"
          }
        },
        "11036c6b1ba840e2aef020b47ef45bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131a7afb016c47038ac1970ec57c4f5b",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_648a65f1f2004618a3e764836cb1b73c",
            "value": 440473133
          }
        },
        "2f96d317ba404ca1b1495e554f29a42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be43f644efd4a59a1639f83a97913e0",
            "placeholder": "​",
            "style": "IPY_MODEL_2676d93c348a4aa5b9e1d4d82d311d2a",
            "value": " 420M/420M [00:07&lt;00:00, 57.3MB/s]"
          }
        },
        "9c0db53f9dff4832a2e23896f0a4d7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0101c5ec84cd4339a4b28e5b7a9a9a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2a88c23f06402fb23d6ffeaaf429be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "131a7afb016c47038ac1970ec57c4f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "648a65f1f2004618a3e764836cb1b73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2be43f644efd4a59a1639f83a97913e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2676d93c348a4aa5b9e1d4d82d311d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}